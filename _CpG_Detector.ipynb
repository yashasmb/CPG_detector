{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G4T6QHHOnfcQ"
   },
   "source": [
    "# Part 1: Build CpG Detector\n",
    "\n",
    "Here we have a simple problem, given a DNA sequence (of N, A, C, G, T), count the number of CpGs in the sequence (consecutive CGs).\n",
    "\n",
    "We have defined a few helper functions / parameters for performing this task.\n",
    "\n",
    "We need you to build a LSTM model and train it to complish this task in PyTorch.\n",
    "\n",
    "A good solution will be a model that can be trained, with high confidence in correctness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "mfS4cLmZD2oB"
   },
   "outputs": [],
   "source": [
    "from typing import Sequence\n",
    "from functools import partial\n",
    "import random\n",
    "import torch\n",
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "_f-brPAvKvTn"
   },
   "outputs": [],
   "source": [
    "# DO NOT CHANGE HERE\n",
    "def set_seed(seed=13):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "set_seed(13)\n",
    "\n",
    "# Use this for getting x label\n",
    "def rand_sequence(n_seqs: int, seq_len: int=128) -> Sequence[int]:\n",
    "    for i in range(n_seqs):\n",
    "        yield [random.randint(0, 4) for _ in range(seq_len)]\n",
    "\n",
    "# Use this for getting y label\n",
    "def count_cpgs(seq: str) -> int:\n",
    "    cgs = 0\n",
    "    for i in range(0, len(seq) - 1):\n",
    "        dimer = seq[i:i+2]\n",
    "        # note that seq is a string, not a list\n",
    "        if dimer == \"CG\":\n",
    "            cgs += 1\n",
    "    return cgs\n",
    "\n",
    "# Alphabet helpers   \n",
    "alphabet = 'NACGT'\n",
    "dna2int = { a: i for a, i in zip(alphabet, range(5))}\n",
    "int2dna = { i: a for a, i in zip(alphabet, range(5))}\n",
    "\n",
    "intseq_to_dnaseq = partial(map, int2dna.get)\n",
    "dnaseq_to_intseq = partial(map, dna2int.get)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3, 4, 0]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#understanding the code\n",
    "dna_sequence = \"ACGTN\"\n",
    "int_sequence = list(dnaseq_to_intseq(dna_sequence))\n",
    "int_sequence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N 0\n",
      "A 1\n",
      "C 2\n",
      "G 3\n",
      "T 4\n",
      "0 N\n",
      "1 A\n",
      "2 C\n",
      "3 G\n",
      "4 T\n"
     ]
    }
   ],
   "source": [
    "#understanding the code\n",
    "for a, i in zip(alphabet, range(5)):\n",
    "    print(a,i)\n",
    "for a, i in zip(alphabet, range(5)):\n",
    "    print(i,a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2, 2, 1, 1, 1, 1, 1, 1, 0, 4, 1, 2, 0, 3, 1, 4, 0, 2, 1, 0, 2, 3, 3, 1, 2, 2, 1, 3, 4, 4, 3, 2, 3, 2, 0, 2, 4, 2, 3, 4, 4, 1, 3, 3, 4, 1, 2, 1, 1, 4, 2, 2, 2, 3, 2, 4, 2, 3, 1, 4, 3, 4, 1, 4, 1, 1, 2, 1, 0, 3, 3, 3, 0, 3, 0, 1, 1, 3, 3, 2, 1, 3, 2, 2, 1, 2, 4, 1, 4, 1, 3, 1, 4, 0, 4, 4, 0, 2, 4, 4, 2, 1, 2, 1, 1, 4, 0, 1, 1, 0, 3, 4, 4, 4, 0, 3, 2, 0, 4, 0, 1, 2, 0, 3, 2, 2, 4, 4], [0, 3, 4, 2, 0, 0, 2, 2, 1, 3, 4, 4, 4, 3, 1, 1, 2, 0, 3, 4, 1, 1, 2, 3, 1, 2, 3, 4, 1, 2, 1, 4, 2, 3, 1, 2, 3, 0, 2, 3, 3, 0, 0, 0, 4, 0, 2, 1, 3, 3, 4, 3, 2, 0, 2, 4, 3, 1, 1, 0, 0, 2, 1, 1, 2, 2, 4, 3, 2, 0, 2, 1, 0, 2, 3, 3, 4, 4, 3, 0, 2, 4, 2, 1, 0, 2, 1, 4, 1, 0, 1, 1, 0, 3, 2, 0, 2, 2, 1, 0, 1, 1, 4, 3, 1, 4, 3, 4, 0, 4, 0, 0, 4, 1, 4, 2, 4, 3, 2, 1, 4, 2, 2, 0, 2, 0, 0, 1], [0, 0, 4, 2, 0, 2, 3, 1, 4, 2, 0, 0, 0, 2, 3, 3, 3, 3, 2, 1, 1, 3, 2, 0, 4, 0, 4, 2, 2, 2, 1, 1, 2, 3, 1, 3, 3, 2, 1, 3, 4, 4, 3, 1, 3, 3, 1, 0, 4, 0, 3, 4, 1, 1, 0, 0, 4, 1, 2, 0, 3, 4, 4, 0, 1, 3, 0, 4, 0, 1, 2, 4, 1, 0, 4, 3, 2, 1, 3, 0, 4, 0, 1, 2, 4, 4, 0, 4, 3, 2, 1, 4, 0, 4, 3, 1, 4, 0, 0, 2, 1, 3, 2, 1, 2, 1, 2, 4, 0, 2, 1, 1, 1, 4, 0, 0, 4, 1, 4, 4, 0, 3, 2, 3, 4, 4, 3, 4], [4, 3, 0, 3, 4, 2, 2, 3, 0, 1, 2, 3, 4, 0, 3, 3, 2, 0, 3, 3, 3, 3, 4, 0, 0, 2, 1, 0, 1, 4, 2, 2, 4, 1, 3, 4, 2, 0, 1, 0, 0, 1, 0, 4, 3, 1, 2, 1, 0, 1, 1, 0, 0, 1, 3, 4, 1, 3, 0, 3, 4, 1, 0, 0, 2, 4, 0, 4, 4, 1, 0, 3, 2, 3, 2, 1, 2, 2, 4, 4, 3, 2, 2, 1, 0, 0, 1, 0, 0, 2, 1, 1, 4, 2, 0, 0, 3, 3, 4, 0, 0, 4, 4, 3, 1, 3, 1, 3, 2, 2, 0, 0, 3, 0, 0, 2, 3, 0, 3, 1, 0, 4, 1, 1, 2, 1, 3, 3], [0, 2, 2, 2, 2, 1, 0, 1, 1, 4, 1, 3, 0, 4, 3, 0, 3, 3, 4, 1, 1, 4, 3, 0, 3, 3, 2, 3, 3, 2, 0, 4, 1, 3, 1, 4, 4, 0, 3, 3, 0, 4, 4, 3, 1, 4, 0, 4, 1, 0, 1, 3, 0, 3, 2, 3, 0, 2, 1, 3, 3, 4, 1, 3, 1, 3, 4, 3, 0, 3, 3, 1, 1, 4, 3, 1, 0, 0, 0, 3, 4, 4, 3, 3, 4, 1, 3, 0, 3, 3, 4, 3, 0, 4, 4, 4, 0, 0, 3, 1, 1, 0, 0, 3, 4, 1, 3, 3, 0, 3, 0, 1, 2, 3, 4, 1, 1, 1, 0, 1, 4, 0, 2, 1, 3, 1, 3, 0]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['CCAAAAAANTACNGATNCANCGGACCAGTTGCGCNCTCGTTAGGTACAATCCCGCTCGATGTATAACANGGGNGNAAGGCAGCCACTATAGATNTTNCTTCACAATNAANGTTTNGCNTNACNGCCTT',\n",
       " 'NGTCNNCCAGTTTGAACNGTAACGACGTACATCGACGNCGGNNNTNCAGGTGCNCTGAANNCAACCTGCNCANCGGTTGNCTCANCATANAANGCNCCANAATGATGTNTNNTATCTGCATCCNCNNA',\n",
       " 'NNTCNCGATCNNNCGGGGCAAGCNTNTCCCAACGAGGCAGTTGAGGANTNGTAANNTACNGTTNAGNTNACTANTGCAGNTNACTTNTGCATNTGATNNCAGCACACTNCAAATNNTATTNGCGTTGT',\n",
       " 'TGNGTCCGNACGTNGGCNGGGGTNNCANATCCTAGTCNANNANTGACANAANNAGTAGNGTANNCTNTTANGCGCACCTTGCCANNANNCAATCNNGGTNNTTGAGAGCCNNGNNCGNGANTAACAGG',\n",
       " 'NCCCCANAATAGNTGNGGTAATGNGGCGGCNTAGATTNGGNTTGATNTANAGNGCGNCAGGTAGAGTGNGGAATGANNNGTTGGTAGNGGTGNTTTNNGAANNGTAGGNGNACGTAAANATNCAGAGN']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#understanding the code\n",
    "X_dna_seqs_train = list(rand_sequence(5))\n",
    "print(X_dna_seqs_train)\n",
    "temp = [\"\".join(intseq_to_dnaseq(seq)) for seq in X_dna_seqs_train]\n",
    "temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 383,
     "status": "ok",
     "timestamp": 1651686469847,
     "user": {
      "displayName": "Ylex",
      "userId": "01820639168093643789"
     },
     "user_tz": 240
    },
    "id": "VK9Qg5GHYxOb",
    "outputId": "0a00bbb6-d9ac-4cf8-ed84-b55b335d7f51"
   },
   "outputs": [],
   "source": [
    "# we prepared two datasets for training and evaluation\n",
    "# training data scale we set to 2048\n",
    "# we test on 512\n",
    "\n",
    "def prepare_data(num_samples=100):\n",
    "    # prepared the training and test data\n",
    "    # you need to call rand_sequence and count_cpgs here to create the dataset\n",
    "    # step 1\n",
    "    X_dna_seqs_train = list(rand_sequence(num_samples))\n",
    "    \"\"\"\n",
    "    hint:\n",
    "        1. You can check X_dna_seqs_train by print, the data is ids which is your training X \n",
    "        2. You first convert ids back to DNA sequence\n",
    "        3. Then you run count_cpgs which will yield CGs counts - this will be the labels (Y)\n",
    "    \"\"\"\n",
    "    #step2\n",
    "    temp = [\"\".join(intseq_to_dnaseq(seq)) for seq in X_dna_seqs_train] # use intseq_to_dnaseq here to convert ids back to DNA seqs\n",
    "    #step3\n",
    "    y_dna_seqs =[count_cpgs(seq) for seq in temp] # use count_cpgs here to generate labels with temp generated in step2\n",
    "    \n",
    "    return X_dna_seqs_train, y_dna_seqs\n",
    "    \n",
    "train_x, train_y = prepare_data(2048)\n",
    "test_x, test_y = prepare_data(512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "LSTM_HIDDEN = 128          # Number of hidden units in LSTM layer (can be increased for more complex models)\n",
    "LSTM_LAYER = 2             # Number of LSTM layers (2-3 is typical for moderate complexity)\n",
    "batch_size = 64            # Size of each mini-batch during training\n",
    "learning_rate = 0.001      # Learning rate for optimization (you can try reducing it for better accuracy)\n",
    "epoch_num = 20 \n",
    "input_size = 128\n",
    "output_size = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yasha\\AppData\\Local\\Temp\\ipykernel_32788\\4031845922.py:6: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  train_x = torch.tensor(train_x)\n",
      "C:\\Users\\yasha\\AppData\\Local\\Temp\\ipykernel_32788\\4031845922.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  train_y = torch.tensor(train_y)\n",
      "C:\\Users\\yasha\\AppData\\Local\\Temp\\ipykernel_32788\\4031845922.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  test_x = torch.tensor(test_x)\n",
      "C:\\Users\\yasha\\AppData\\Local\\Temp\\ipykernel_32788\\4031845922.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  test_y = torch.tensor(test_y)\n"
     ]
    }
   ],
   "source": [
    "# create data loader\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import TensorDataset\n",
    "\n",
    "# Convert data to PyTorch tensors\n",
    "train_x = torch.tensor(train_x)\n",
    "train_y = torch.tensor(train_y)\n",
    "test_x = torch.tensor(test_x)\n",
    "test_y = torch.tensor(test_y)\n",
    "\n",
    "train_data_loader = DataLoader(TensorDataset(train_x, train_y), batch_size=batch_size)\n",
    "test_Data_loader = DataLoader(TensorDataset(test_x, test_y), batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.utils.data.dataloader.DataLoader'>\n",
      "2\n",
      "<class 'list'>\n"
     ]
    }
   ],
   "source": [
    "print(type(train_data_loader))\n",
    "for a in train_data_loader:\n",
    "    print(len(a))\n",
    "    print(type(a))\n",
    "    break\n",
    "   \n",
    "# the"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "q8fgxrM0LnLy"
   },
   "outputs": [],
   "source": [
    "# Model\n",
    "# class CpGPredictor(torch.nn.Module):\n",
    "#     ''' Simple model that uses a LSTM to count the number of CpGs in a sequence '''\n",
    "#     def __init__(self):\n",
    "#         super(CpGPredictor, self).__init__()\n",
    "#         # TODO complete model, you are free to add whatever layers you need here\n",
    "#         # We do need a lstm and a classifier layer here but you are free to implement them in your way\n",
    "#         self.lstm = ???\n",
    "#         self.classifier = ???\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         # TODO complete forward function\n",
    "#         return logits\n",
    "    \n",
    "class CpGPredictor(torch.nn.Module):\n",
    "    ''' Simple model that uses a LSTM to count the number of CpGs in a sequence '''\n",
    "    def __init__(self, input_size, hidden_size, num_layers, output_size):\n",
    "        super(CpGPredictor, self).__init__()\n",
    "        # We do need a lstm and a classifier layer here but you are free to implement them in your way\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.embedding = torch.nn.Embedding(5, input_size)\n",
    "        self.lstm = torch.nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.fc = torch.nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x)\n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
    "        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
    "        out, _ = self.lstm(x, (h0, c0))\n",
    "        out = self.fc(out[:, -1, :])\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch.nn as nn\n",
    "\n",
    "class CpGPredictor(nn.Module):\n",
    "    ''' Simple model that uses an LSTM to count the number of CpGs in a sequence '''\n",
    "    def __init__(self, input_size, hidden_size, num_layers, output_size):\n",
    "        super(CpGPredictor, self).__init__()\n",
    "        \n",
    "        # LSTM Layer\n",
    "        # input_size: Number of features in the input sequence (e.g., size of each element in the sequence)\n",
    "        # hidden_size: Size of the hidden state (how much information each LSTM unit carries)\n",
    "        # num_layers: Number of LSTM layers stacked together\n",
    "        # batch_first=True: The input tensor should have shape (batch_size, sequence_length, input_size)\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        \n",
    "        # Classifier Layer (fully connected)\n",
    "        # Takes the output from the LSTM and maps it to the final output size (e.g., number of classes)\n",
    "        self.classifier = nn.Linear(hidden_size, output_size)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        '''\n",
    "        Forward pass for the model\n",
    "        x: Input tensor of shape (batch_size, sequence_length, input_size)\n",
    "        '''\n",
    "        # Pass input through LSTM\n",
    "        # lstm_out: The output of the LSTM, containing the hidden states for each timestep\n",
    "        # _ : The hidden state and cell state (not used in this case)\n",
    "        lstm_out, _ = self.lstm(x)\n",
    "        \n",
    "        # Take the output from the last timestep\n",
    "        # We use the output from the final timestep to make predictions\n",
    "        final_hidden_state = lstm_out[:, -1, :]\n",
    "        \n",
    "        # Pass the final hidden state through the classifier to get the logits\n",
    "        logits = self.classifier(final_hidden_state)\n",
    "        \n",
    "        return logits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class CpGPredictor(nn.Module):\n",
    "    ''' Simple model that uses an LSTM to count the number of CpGs in a sequence '''\n",
    "    def __init__(self, input_size, hidden_size, num_layers, output_size):\n",
    "        super(CpGPredictor, self).__init__()\n",
    "        \n",
    "        # LSTM Layer\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        \n",
    "        # Classifier Layer (fully connected)\n",
    "        self.classifier = nn.Linear(hidden_size, output_size)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Pass input through LSTM\n",
    "        lstm_out, _ = self.lstm(x)\n",
    "        \n",
    "        # Take the output from the last timestep\n",
    "        # We use the output from the final timestep to make predictions\n",
    "        # Ensure that we handle the case where the sequence length is 1\n",
    "        if lstm_out.dim() == 2:\n",
    "            final_hidden_state = lstm_out  # If no sequence dimension (e.g., batch_size=1)\n",
    "        else:\n",
    "            final_hidden_state = lstm_out[:, -1, :]  # Last timestep for each sequence in the batch\n",
    "        \n",
    "        # Pass the final hidden state through the classifier to get the logits\n",
    "        logits = self.classifier(final_hidden_state)\n",
    "        # Take the output from the last timestep\n",
    "        \n",
    "        # Pass through classifier to get the logits\n",
    "        logits = self.classifier(final_hidden_state)\n",
    "        \n",
    "        return logits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CpGPredictor(torch.nn.Module):\n",
    "    ''' Simple model that uses an LSTM to count the number of CpGs in a sequence '''\n",
    "    def __init__(self, input_size, hidden_size, num_layers, output_size, dropout_prob=0.5):\n",
    "        super(CpGPredictor, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.embedding = torch.nn.Embedding(5, input_size)\n",
    "        self.lstm = torch.nn.LSTM(\n",
    "            input_size, hidden_size, num_layers, batch_first=True, dropout=dropout_prob if num_layers > 1 else 0.0\n",
    "        )\n",
    "        # self.dropout = torch.nn.Dropout(dropout_prob)  # Dropout layer\n",
    "        self.fc = torch.nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x)  # Apply embedding\n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
    "        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
    "        out, _ = self.lstm(x, (h0, c0))  # LSTM with initialized states\n",
    "        # out = self.dropout(out[:, -1, :])  # Apply dropout to the output of the last LSTM step\n",
    "        out = self.fc(out)  # Fully connected layer\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# init model / loss function / optimizer etc.\n",
    "\n",
    "# model = CpGPredictor(input_size, LSTM_HIDDEN, LSTM_LAYER, output_size)\n",
    "# loss_fn = torch.nn.MSELoss()\n",
    "# optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Instantiate the model\n",
    "model = CpGPredictor(input_size=input_size, hidden_size=LSTM_HIDDEN, num_layers=LSTM_LAYER, output_size=output_size)\n",
    "\n",
    "\n",
    "loss_fn = torch.nn.MSELoss()\n",
    "\n",
    "# Define the optimizer (Adam optimizer)\n",
    "optimizer = optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)  # Reduced learning rate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training (you can modify the code below)\n",
    "t_loss = .0\n",
    "model.train()\n",
    "model.zero_grad()\n",
    "for _ in range(epoch_num):\n",
    "    for batch in train_data_loader:\n",
    "        #TODO complete training loop\n",
    "        t_loss += loss.item()\n",
    "        loss.backward()\n",
    "\n",
    "    print(t_loss)\n",
    "    t_loss = .0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (128) must match the size of tensor b (64) at non-singleton dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[65], line 14\u001b[0m\n\u001b[0;32m     12\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\u001b[38;5;66;03m# Zero the gradients from the previous step\u001b[39;00m\n\u001b[0;32m     13\u001b[0m logits \u001b[38;5;241m=\u001b[39m model(inputs) \u001b[38;5;66;03m# Forward pass: Compute predicted outputs by passing inputs to the model      \u001b[39;00m\n\u001b[1;32m---> 14\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[43mloss_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlogits\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtargets\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;66;03m# Calculate the loss (use BCEWithLogitsLoss for binary classification) \u001b[39;00m\n\u001b[0;32m     15\u001b[0m epoch_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\u001b[38;5;66;03m# Accumulate the loss for the epoch      \u001b[39;00m\n\u001b[0;32m     16\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward() \u001b[38;5;66;03m# Backward pass: Compute gradients of the loss w.r.t. model parameters  \u001b[39;00m\n",
      "File \u001b[1;32me:\\python_project\\proj_env\\lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32me:\\python_project\\proj_env\\lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32me:\\python_project\\proj_env\\lib\\site-packages\\torch\\nn\\modules\\loss.py:608\u001b[0m, in \u001b[0;36mMSELoss.forward\u001b[1;34m(self, input, target)\u001b[0m\n\u001b[0;32m    607\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor, target: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 608\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmse_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduction\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreduction\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32me:\\python_project\\proj_env\\lib\\site-packages\\torch\\nn\\functional.py:3791\u001b[0m, in \u001b[0;36mmse_loss\u001b[1;34m(input, target, size_average, reduce, reduction)\u001b[0m\n\u001b[0;32m   3788\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m size_average \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m reduce \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   3789\u001b[0m     reduction \u001b[38;5;241m=\u001b[39m _Reduction\u001b[38;5;241m.\u001b[39mlegacy_get_string(size_average, reduce)\n\u001b[1;32m-> 3791\u001b[0m expanded_input, expanded_target \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbroadcast_tensors\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3792\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_nn\u001b[38;5;241m.\u001b[39mmse_loss(\n\u001b[0;32m   3793\u001b[0m     expanded_input, expanded_target, _Reduction\u001b[38;5;241m.\u001b[39mget_enum(reduction)\n\u001b[0;32m   3794\u001b[0m )\n",
      "File \u001b[1;32me:\\python_project\\proj_env\\lib\\site-packages\\torch\\functional.py:76\u001b[0m, in \u001b[0;36mbroadcast_tensors\u001b[1;34m(*tensors)\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function(tensors):\n\u001b[0;32m     75\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(broadcast_tensors, tensors, \u001b[38;5;241m*\u001b[39mtensors)\n\u001b[1;32m---> 76\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_VF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbroadcast_tensors\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: The size of tensor a (128) must match the size of tensor b (64) at non-singleton dimension 1"
     ]
    }
   ],
   "source": [
    "\n",
    "t_loss = 0.0\n",
    "model.train()\n",
    "\n",
    "\n",
    "for epoch in range(epoch_num):\n",
    "    # Initialize the running total loss for this epoch\n",
    "    epoch_loss = 0.0\n",
    "    for batch in train_data_loader:\n",
    "        inputs, targets = batch  # Unpack the batch (assuming each batch contains inputs and targets)    \n",
    "        # inputs = inputs.float()\n",
    "        targets = targets.view(-1, 1).float()  # Reshaping targets to (batch_size, 1)\n",
    "        optimizer.zero_grad()# Zero the gradients from the previous step\n",
    "        logits = model(inputs) # Forward pass: Compute predicted outputs by passing inputs to the model      \n",
    "        loss = loss_fn(logits, targets)# Calculate the loss (use BCEWithLogitsLoss for binary classification) \n",
    "        epoch_loss += loss.item()# Accumulate the loss for the epoch      \n",
    "        loss.backward() # Backward pass: Compute gradients of the loss w.r.t. model parameters  \n",
    "        # torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "        optimizer.step()  # Update the model parameters\n",
    "    print(f\"Epoch [{epoch+1}/{epoch_num}], Loss: {epoch_loss}\")\n",
    "    t_loss = 0.0 # Reset the epoch loss for the next epoch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# eval (you can modify the code below)\n",
    "model.eval()\n",
    "\n",
    "res_gs = []\n",
    "res_pred = []\n",
    "\n",
    "for batch in test_data_loader:\n",
    "    # TODO complete inference loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO complete evaluation of the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TMrRf_aVDRJm"
   },
   "source": [
    "# Part 2: what if the DNA sequences are not the same length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hint we will need following imports\n",
    "from torch.nn.utils.rnn import pad_sequence, pack_padded_sequence, pad_packed_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AKvG-MNuXJr9"
   },
   "outputs": [],
   "source": [
    "# DO NOT CHANGE HERE\n",
    "random.seed(13)\n",
    "\n",
    "# Use this for getting x label\n",
    "def rand_sequence_var_len(n_seqs: int, lb: int=16, ub: int=128) -> Sequence[int]:\n",
    "    for i in range(n_seqs):\n",
    "        seq_len = random.randint(lb, ub)\n",
    "        yield [random.randint(1, 5) for _ in range(seq_len)]\n",
    "\n",
    "\n",
    "# Use this for getting y label\n",
    "def count_cpgs(seq: str) -> int:\n",
    "    cgs = 0\n",
    "    for i in range(0, len(seq) - 1):\n",
    "        dimer = seq[i:i+2]\n",
    "        # note that seq is a string, not a list\n",
    "        if dimer == \"CG\":\n",
    "            cgs += 1\n",
    "    return cgs\n",
    "\n",
    "\n",
    "# Alphabet helpers   \n",
    "alphabet = 'NACGT'\n",
    "dna2int = {a: i for a, i in zip(alphabet, range(1, 6))}\n",
    "int2dna = {i: a for a, i in zip(alphabet, range(1, 6))}\n",
    "dna2int.update({\"pad\": 0})\n",
    "int2dna.update({0: \"<pad>\"})\n",
    "\n",
    "intseq_to_dnaseq = partial(map, int2dna.get)\n",
    "dnaseq_to_intseq = partial(map, dna2int.get)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO complete the task based on the change\n",
    "def prepare_data(num_samples=100, min_len=16, max_len=128):\n",
    "    # TODO prepared the training and test data\n",
    "    # you need to call rand_sequence and count_cpgs here to create the dataset\n",
    "    #step 1\n",
    "    X_dna_seqs_train = list(rand_sequence_var_len(num_samples, min_len, max_len))\n",
    "    #step 2\n",
    "    temp = ???\n",
    "    #step3\n",
    "    y_dna_seqs = ???\n",
    "    \n",
    "    return X_dna_seqs_train, y_dna_seqs\n",
    "    \n",
    "    \n",
    "min_len, max_len = 64, 128\n",
    "train_x, train_y = prepare_data(2048, min_len, max_len)\n",
    "test_x, test_y = prepare_data(512, min_len, max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, lists, labels) -> None:\n",
    "        self.lists = lists\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return torch.LongTensor(self.lists[index]), self.labels[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.lists)\n",
    "\n",
    "    \n",
    "# this will be a collate_fn for dataloader to pad sequence  \n",
    "class PadSequence:\n",
    "    #TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO complete the rest"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Xi Yangs Copy of broken-nn-template.ipynb",
   "provenance": [
    {
     "file_id": "13GlbI_pdKNES8I718iwl1KNnMZ73iOOn",
     "timestamp": 1651680757732
    }
   ]
  },
  "kernelspec": {
   "display_name": "proj_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
