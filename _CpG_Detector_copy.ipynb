{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G4T6QHHOnfcQ"
   },
   "source": [
    "# Part 1: Build CpG Detector\n",
    "\n",
    "Here we have a simple problem, given a DNA sequence (of N, A, C, G, T), count the number of CpGs in the sequence (consecutive CGs).\n",
    "\n",
    "We have defined a few helper functions / parameters for performing this task.\n",
    "\n",
    "We need you to build a LSTM model and train it to complish this task in PyTorch.\n",
    "\n",
    "A good solution will be a model that can be trained, with high confidence in correctness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "mfS4cLmZD2oB"
   },
   "outputs": [],
   "source": [
    "from typing import Sequence\n",
    "from functools import partial\n",
    "import random\n",
    "import torch\n",
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "_f-brPAvKvTn"
   },
   "outputs": [],
   "source": [
    "# DO NOT CHANGE HERE\n",
    "def set_seed(seed=13):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)    \n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "set_seed(13)\n",
    "\n",
    "# Use this for getting x label\n",
    "def rand_sequence(n_seqs: int, seq_len: int=128) -> Sequence[int]:\n",
    "    for i in range(n_seqs):\n",
    "        yield [random.randint(0, 4) for _ in range(seq_len)]\n",
    "\n",
    "# Use this for getting y label\n",
    "def count_cpgs(seq: str) -> int:\n",
    "    cgs = 0\n",
    "    for i in range(0, len(seq) - 1):\n",
    "        dimer = seq[i:i+2]\n",
    "        # note that seq is a string, not a list\n",
    "        if dimer == \"CG\":\n",
    "            cgs += 1\n",
    "    return cgs\n",
    "\n",
    "# Alphabet helpers   \n",
    "alphabet = 'NACGT'\n",
    "dna2int = { a: i for a, i in zip(alphabet, range(5))}\n",
    "int2dna = { i: a for a, i in zip(alphabet, range(5))}\n",
    "\n",
    "intseq_to_dnaseq = partial(map, int2dna.get)\n",
    "dnaseq_to_intseq = partial(map, dna2int.get)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3, 4, 0]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dna_sequence = \"ACGTN\"\n",
    "int_sequence = list(dnaseq_to_intseq(dna_sequence))\n",
    "int_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N 0\n",
      "A 1\n",
      "C 2\n",
      "G 3\n",
      "T 4\n"
     ]
    }
   ],
   "source": [
    "for a, i in zip(alphabet, range(5)):\n",
    "    print(a,i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 N\n",
      "1 A\n",
      "2 C\n",
      "3 G\n",
      "4 T\n"
     ]
    }
   ],
   "source": [
    "for a, i in zip(alphabet, range(5)):\n",
    "    print(i,a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "12.4\n",
      "NVIDIA GeForce RTX 4060 Laptop GPU\n"
     ]
    }
   ],
   "source": [
    "# import torch\n",
    "print(torch.cuda.is_available())  # Should return True\n",
    "print(torch.version.cuda)         # Should match your CUDA version\n",
    "print(torch.cuda.get_device_name(0))  # Name of your GPU\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0, 1, 2, 3, 0, 1, 0, 2, 2, 0, 0, 1, 3, 0, 2, 0, 3, 1, 3, 1, 3, 1, 2, 4, 2, 3, 1, 0, 3, 4, 4, 0, 2, 0, 4, 1, 2, 0, 4, 1, 0, 1, 2, 1, 2, 4, 2, 2, 0, 2, 1, 3, 1, 1, 0, 4, 2, 0, 0, 0, 2, 4, 0, 4, 0, 0, 3, 0, 2, 0, 3, 0, 2, 0, 4, 2, 0, 1, 3, 4, 2, 4, 4, 2, 2, 1, 3, 1, 4, 0, 3, 2, 1, 3, 4, 2, 1, 1, 1, 0, 2, 0, 4, 3, 1, 1, 0, 2, 3, 4, 4, 3, 2, 0, 0, 3, 4, 1, 3, 1, 1, 3, 0, 4, 4, 2, 4, 4], [0, 0, 4, 0, 0, 3, 2, 3, 3, 3, 4, 2, 4, 0, 0, 0, 2, 1, 4, 0, 0, 1, 4, 1, 0, 0, 0, 4, 3, 2, 3, 1, 1, 3, 0, 2, 0, 1, 2, 2, 0, 3, 0, 0, 2, 4, 0, 1, 0, 4, 1, 1, 2, 2, 0, 3, 3, 3, 1, 4, 1, 3, 0, 1, 0, 4, 2, 0, 3, 0, 3, 2, 0, 0, 4, 4, 4, 4, 3, 1, 3, 3, 1, 1, 3, 1, 4, 0, 0, 0, 1, 1, 0, 4, 1, 1, 3, 3, 1, 2, 2, 3, 1, 4, 4, 3, 3, 1, 1, 2, 2, 4, 1, 1, 1, 4, 0, 3, 4, 4, 4, 2, 3, 0, 0, 1, 4, 2], [0, 0, 1, 3, 3, 0, 4, 3, 1, 0, 0, 4, 0, 1, 1, 1, 2, 1, 2, 0, 3, 1, 0, 0, 4, 2, 2, 2, 1, 3, 3, 2, 2, 0, 3, 2, 0, 0, 3, 4, 1, 2, 0, 0, 1, 1, 3, 1, 1, 4, 1, 1, 2, 0, 3, 4, 3, 1, 0, 3, 3, 3, 4, 2, 2, 3, 0, 0, 2, 4, 1, 1, 0, 3, 3, 2, 0, 0, 2, 0, 1, 4, 4, 0, 3, 3, 4, 3, 2, 2, 4, 2, 1, 3, 2, 1, 1, 2, 2, 1, 4, 4, 3, 1, 0, 4, 2, 3, 0, 1, 2, 4, 4, 2, 4, 1, 1, 4, 0, 1, 4, 3, 0, 4, 2, 3, 2, 3], [0, 4, 1, 1, 3, 4, 4, 0, 1, 2, 4, 1, 3, 0, 1, 1, 4, 2, 1, 1, 0, 4, 3, 3, 4, 0, 3, 2, 0, 2, 3, 3, 0, 1, 4, 0, 0, 4, 4, 0, 1, 3, 4, 4, 4, 1, 3, 0, 3, 1, 4, 0, 4, 0, 2, 0, 2, 4, 3, 1, 1, 2, 1, 3, 0, 1, 3, 3, 3, 1, 1, 3, 0, 1, 2, 0, 3, 4, 4, 1, 0, 3, 3, 4, 2, 0, 4, 4, 3, 0, 1, 2, 4, 3, 2, 1, 2, 4, 1, 1, 0, 0, 1, 3, 4, 0, 3, 2, 2, 0, 4, 3, 3, 1, 2, 0, 4, 0, 1, 0, 2, 3, 3, 0, 1, 2, 0, 4], [0, 1, 2, 2, 4, 3, 3, 2, 1, 1, 1, 1, 2, 3, 2, 0, 2, 1, 0, 2, 4, 1, 1, 1, 2, 0, 2, 4, 3, 2, 3, 1, 0, 3, 0, 4, 0, 0, 1, 2, 3, 4, 0, 2, 0, 1, 0, 1, 2, 4, 3, 4, 1, 4, 4, 4, 0, 0, 3, 2, 2, 2, 2, 4, 3, 4, 4, 0, 3, 2, 1, 1, 0, 1, 2, 4, 2, 4, 4, 3, 0, 1, 4, 1, 1, 4, 4, 0, 4, 0, 0, 2, 1, 1, 2, 4, 3, 4, 3, 1, 1, 2, 0, 1, 4, 3, 1, 0, 4, 1, 0, 1, 4, 2, 2, 4, 3, 4, 0, 4, 4, 4, 4, 4, 0, 3, 3, 1]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['NACGNANCCNNAGNCNGAGAGACTCGANGTTNCNTACNTANACACTCCNCAGAANTCNNNCTNTNNGNCNGNCNTCNAGTCTTCCAGATNGCAGTCAAANCNTGAANCGTTGCNNGTAGAAGNTTCTT',\n",
       " 'NNTNNGCGGGTCTNNNCATNNATANNNTGCGAAGNCNACCNGNNCTNANTAACCNGGGATAGNANTCNGNGCNNTTTTGAGGAAGATNNNAANTAAGGACCGATTGGAACCTAAATNGTTTCGNNATC',\n",
       " 'NNAGGNTGANNTNAAACACNGANNTCCCAGGCCNGCNNGTACNNAAGAATAACNGTGANGGGTCCGNNCTAANGGCNNCNATTNGGTGCCTCAGCAACCATTGANTCGNACTTCTAATNATGNTCGCG',\n",
       " 'NTAAGTTNACTAGNAATCAANTGGTNGCNCGGNATNNTTNAGTTTAGNGATNTNCNCTGAACAGNAGGGAAGNACNGTTANGGTCNTTGNACTGCACTAANNAGTNGCCNTGGACNTNANCGGNACNT',\n",
       " 'NACCTGGCAAAACGCNCANCTAAACNCTGCGANGNTNNACGTNCNANACTGTATTTNNGCCCCTGTTNGCAANACTCTTGNATAATTNTNNCAACTGTGAACNATGANTANATCCTGTNTTTTTNGGA']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_dna_seqs_train = list(rand_sequence(5))\n",
    "print(X_dna_seqs_train)\n",
    "temp = [\"\".join(intseq_to_dnaseq(seq)) for seq in X_dna_seqs_train]\n",
    "temp\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3, 4, 4, 2, 3]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a=[count_cpgs(seq) for seq in temp]\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 383,
     "status": "ok",
     "timestamp": 1651686469847,
     "user": {
      "displayName": "Ylex",
      "userId": "01820639168093643789"
     },
     "user_tz": 240
    },
    "id": "VK9Qg5GHYxOb",
    "outputId": "0a00bbb6-d9ac-4cf8-ed84-b55b335d7f51"
   },
   "outputs": [],
   "source": [
    "# we prepared two datasets for training and evaluation\n",
    "# training data scale we set to 2048\n",
    "# we test on 512\n",
    "\n",
    "def prepare_data(num_samples=100):\n",
    "    # prepared the training and test data\n",
    "    # you need to call rand_sequence and count_cpgs here to create the dataset\n",
    "    # step 1\n",
    "    X_dna_seqs_train = list(rand_sequence(num_samples))\n",
    "    # print(X_dna_seqs_train)\n",
    "    \"\"\"\n",
    "    hint:\n",
    "        1. You can check X_dna_seqs_train by print, the data is ids which is your training X \n",
    "        2. You first convert ids back to DNA sequence\n",
    "        3. Then you run count_cpgs which will yield CGs counts - this will be the labels (Y)\n",
    "    \"\"\"\n",
    "    #step2\n",
    "    temp = [\"\".join(intseq_to_dnaseq(seq)) for seq in X_dna_seqs_train] # use intseq_to_dnaseq here to convert ids back to DNA seqs\n",
    "    #step3\n",
    "    y_dna_seqs = [count_cpgs(seq) for seq in temp] # use count_cpgs here to generate labels with temp generated in step2\n",
    "    \n",
    "    return X_dna_seqs_train, y_dna_seqs\n",
    "    \n",
    "train_x, train_y = prepare_data(2048)\n",
    "test_x, test_y = prepare_data(512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 2, 3, 2, 0, 2, 4, 1, 1, 3, 0, 3, 4, 2, 3, 0, 0, 2, 1, 3, 2, 4, 0, 1, 1, 3, 4, 0, 2, 1, 1, 1, 3, 3, 4, 4, 1, 0, 2, 4, 0, 2, 2, 4, 1, 1, 1, 2, 3, 4, 0, 1, 4, 0, 2, 2, 1, 4, 2, 3, 1, 0, 1, 2, 2, 3, 2, 2, 3, 2, 0, 3, 4, 0, 0, 4, 3, 2, 0, 2, 0, 0, 1, 3, 4, 1, 0, 0, 4, 0, 0, 3, 1, 4, 0, 0, 3, 1, 4, 1, 3, 0, 4, 3, 2, 3, 0, 1, 3, 1, 4, 4, 0, 1, 3, 1, 2, 4, 3, 4, 1, 1, 1, 4, 2, 0, 2, 4]\n",
      "7\n"
     ]
    }
   ],
   "source": [
    "print(train_x[0])\n",
    "print(train_y[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'CCACNGTCGTAACGNNCGGNNTACCTCGGCAAGGCNAGATTATNTCGNCCANGTGTGTACCATNTNAGNNGTAAGGAGNANACCCCNAGGGNANNGCGCTNCGCAGAAGNTAANTAGCNNTNNNNTNT'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\".join(intseq_to_dnaseq(train_x[0]))\n",
    "# \"\".join(intseq_to_dnaseq(seq)) for seq in X_dna_seqs_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# some config\n",
    "\n",
    "LSTM_HIDDEN = 128          # Number of hidden units in LSTM layer (can be increased for more complex models)\n",
    "LSTM_LAYER = 2             # Number of LSTM layers (2-3 is typical for moderate complexity)\n",
    "batch_size = 64            # Size of each mini-batch during training\n",
    "learning_rate = 0.001      # Learning rate for optimization (you can try reducing it for better accuracy)\n",
    "epoch_num = 20 \n",
    "input_size = 128\n",
    "output_size = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yasha\\AppData\\Local\\Temp\\ipykernel_30384\\1165688285.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  train_x = torch.tensor(train_x)\n",
      "C:\\Users\\yasha\\AppData\\Local\\Temp\\ipykernel_30384\\1165688285.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  train_y = torch.tensor(train_y)\n",
      "C:\\Users\\yasha\\AppData\\Local\\Temp\\ipykernel_30384\\1165688285.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  test_x = torch.tensor(test_x)\n",
      "C:\\Users\\yasha\\AppData\\Local\\Temp\\ipykernel_30384\\1165688285.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  test_y = torch.tensor(test_y)\n"
     ]
    }
   ],
   "source": [
    "# create data loader\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import TensorDataset\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Convert data to PyTorch tensors\n",
    "train_x = torch.tensor(train_x)\n",
    "train_y = torch.tensor(train_y)\n",
    "test_x = torch.tensor(test_x)\n",
    "test_y = torch.tensor(test_y)\n",
    "train_data_loader = DataLoader(TensorDataset(train_x, train_y), batch_size=batch_size)\n",
    "test_data_loader = DataLoader(TensorDataset(test_x, test_y), batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "id": "q8fgxrM0LnLy"
   },
   "outputs": [],
   "source": [
    "# Model\n",
    "class CpGPredictor(torch.nn.Module):\n",
    "    ''' Simple model that uses a LSTM to count the number of CpGs in a sequence '''\n",
    "    def __init__(self,input_size=5, hidden_size=128, num_layers=1, output_size=1):\n",
    "        super(CpGPredictor, self).__init__()\n",
    "        # TODO complete model, you are free to add whatever layers you need here\n",
    "        # We do need a lstm and a classifier layer here but you are free to implement them in your way\n",
    "        self.lstm = torch.nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.classifier = torch.nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x)\n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
    "        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
    "        out, _ = self.lstm(x, (h0, c0))\n",
    "        logits = self.fc(out[:, -1, :])\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CpGPredictor1(torch.nn.Module):\n",
    "    ''' Simple model that uses an LSTM to count the number of CpGs in a sequence '''\n",
    "    def __init__(self, input_size=5, hidden_size=128, num_layers=1, output_size=1):\n",
    "        super(CpGPredictor, self).__init__()\n",
    "        self.embedding = torch.nn.Embedding(5, input_size)  # Embedding layer for input sequence\n",
    "        self.lstm = torch.nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.classifier = torch.nn.Linear(hidden_size, output_size)  # Linear layer for classification\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Apply embedding layer to input\n",
    "        x = self.embedding(x)\n",
    "        \n",
    "        # Initialize hidden and cell states for LSTM\n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
    "        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
    "        \n",
    "        # Pass through LSTM\n",
    "        out, _ = self.lstm(x, (h0, c0))\n",
    "        \n",
    "        # Apply classifier to the last hidden state\n",
    "        logits = self.classifier(out[:, -1, :])\n",
    "        \n",
    "        return logits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "type object 'CpGPredictor' has no attribute 'summ'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[49], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mCpGPredictor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msumm\u001b[49m)\n",
      "\u001b[1;31mAttributeError\u001b[0m: type object 'CpGPredictor' has no attribute 'summ'"
     ]
    }
   ],
   "source": [
    "# print(CpGPredictor.summ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "class CpGPredictor2(torch.nn.Module):\n",
    "    ''' Simple model that uses an LSTM to count the number of CpGs in a sequence '''\n",
    "    def __init__(self, input_size=5, hidden_size=128, num_layers=1, output_size=1):\n",
    "        super(CpGPredictor2, self).__init__()\n",
    "        \n",
    "        # Embedding layer for the DNA sequence\n",
    "        self.embedding = torch.nn.Embedding(5, input_size)  # 5 possible symbols in DNA\n",
    "        self.lstm = torch.nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.classifier = torch.nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Convert input to LongTensor before passing to embedding\n",
    "        x = x.long()  # Ensure input is of type LongTensor\n",
    "        x = self.embedding(x)  # Apply the embedding layer\n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
    "        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
    "        out, _ = self.lstm(x, (h0, c0))\n",
    "        logits = self.classifier(out[:, -1, :])\n",
    "        return logits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Failed to run torchinfo. See above stack traces for more details. Executed layers up to: []",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "File \u001b[1;32me:\\python_project\\proj_env\\lib\\site-packages\\torchinfo\\torchinfo.py:295\u001b[0m, in \u001b[0;36mforward_pass\u001b[1;34m(model, x, batch_dim, cache_forward_pass, device, mode, **kwargs)\u001b[0m\n\u001b[0;32m    294\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(x, (\u001b[38;5;28mlist\u001b[39m, \u001b[38;5;28mtuple\u001b[39m)):\n\u001b[1;32m--> 295\u001b[0m     _ \u001b[38;5;241m=\u001b[39m model(\u001b[38;5;241m*\u001b[39mx, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    296\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mdict\u001b[39m):\n",
      "File \u001b[1;32me:\\python_project\\proj_env\\lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32me:\\python_project\\proj_env\\lib\\site-packages\\torch\\nn\\modules\\module.py:1844\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1843\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1844\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1845\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[0;32m   1846\u001b[0m     \u001b[38;5;66;03m# run always called hooks if they have not already been run\u001b[39;00m\n\u001b[0;32m   1847\u001b[0m     \u001b[38;5;66;03m# For now only forward hooks have the always_call option but perhaps\u001b[39;00m\n\u001b[0;32m   1848\u001b[0m     \u001b[38;5;66;03m# this functionality should be added to full backward hooks as well.\u001b[39;00m\n",
      "File \u001b[1;32me:\\python_project\\proj_env\\lib\\site-packages\\torch\\nn\\modules\\module.py:1790\u001b[0m, in \u001b[0;36mModule._call_impl.<locals>.inner\u001b[1;34m()\u001b[0m\n\u001b[0;32m   1788\u001b[0m     args \u001b[38;5;241m=\u001b[39m bw_hook\u001b[38;5;241m.\u001b[39msetup_input_hook(args)\n\u001b[1;32m-> 1790\u001b[0m result \u001b[38;5;241m=\u001b[39m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1791\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks:\n",
      "Cell \u001b[1;32mIn[47], line 12\u001b[0m, in \u001b[0;36mCpGPredictor.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m---> 12\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membedding\u001b[49m(x)\n\u001b[0;32m     13\u001b[0m     h0 \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mzeros(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_layers, x\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhidden_size)\u001b[38;5;241m.\u001b[39mto(x\u001b[38;5;241m.\u001b[39mdevice)\n",
      "File \u001b[1;32me:\\python_project\\proj_env\\lib\\site-packages\\torch\\nn\\modules\\module.py:1931\u001b[0m, in \u001b[0;36mModule.__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   1930\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m modules[name]\n\u001b[1;32m-> 1931\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\n\u001b[0;32m   1932\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m object has no attribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1933\u001b[0m )\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'CpGPredictor' object has no attribute 'embedding'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[53], line 7\u001b[0m\n\u001b[0;32m      4\u001b[0m model \u001b[38;5;241m=\u001b[39m CpGPredictor(input_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, hidden_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m128\u001b[39m, num_layers\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, output_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# Print the model summary for an input size (e.g., a batch size of 32, sequence length 128)\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m \u001b[43msummary\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m128\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# (batch_size, sequence_length)\u001b[39;00m\n",
      "File \u001b[1;32me:\\python_project\\proj_env\\lib\\site-packages\\torchinfo\\torchinfo.py:223\u001b[0m, in \u001b[0;36msummary\u001b[1;34m(model, input_size, input_data, batch_dim, cache_forward_pass, col_names, col_width, depth, device, dtypes, mode, row_settings, verbose, **kwargs)\u001b[0m\n\u001b[0;32m    216\u001b[0m validate_user_params(\n\u001b[0;32m    217\u001b[0m     input_data, input_size, columns, col_width, device, dtypes, verbose\n\u001b[0;32m    218\u001b[0m )\n\u001b[0;32m    220\u001b[0m x, correct_input_size \u001b[38;5;241m=\u001b[39m process_input(\n\u001b[0;32m    221\u001b[0m     input_data, input_size, batch_dim, device, dtypes\n\u001b[0;32m    222\u001b[0m )\n\u001b[1;32m--> 223\u001b[0m summary_list \u001b[38;5;241m=\u001b[39m forward_pass(\n\u001b[0;32m    224\u001b[0m     model, x, batch_dim, cache_forward_pass, device, model_mode, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m    225\u001b[0m )\n\u001b[0;32m    226\u001b[0m formatting \u001b[38;5;241m=\u001b[39m FormattingOptions(depth, verbose, columns, col_width, rows)\n\u001b[0;32m    227\u001b[0m results \u001b[38;5;241m=\u001b[39m ModelStatistics(\n\u001b[0;32m    228\u001b[0m     summary_list, correct_input_size, get_total_memory_used(x), formatting\n\u001b[0;32m    229\u001b[0m )\n",
      "File \u001b[1;32me:\\python_project\\proj_env\\lib\\site-packages\\torchinfo\\torchinfo.py:304\u001b[0m, in \u001b[0;36mforward_pass\u001b[1;34m(model, x, batch_dim, cache_forward_pass, device, mode, **kwargs)\u001b[0m\n\u001b[0;32m    302\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    303\u001b[0m     executed_layers \u001b[38;5;241m=\u001b[39m [layer \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m summary_list \u001b[38;5;28;01mif\u001b[39;00m layer\u001b[38;5;241m.\u001b[39mexecuted]\n\u001b[1;32m--> 304\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m    305\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to run torchinfo. See above stack traces for more details. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    306\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExecuted layers up to: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mexecuted_layers\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    307\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01me\u001b[39;00m\n\u001b[0;32m    308\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    309\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m hooks:\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Failed to run torchinfo. See above stack traces for more details. Executed layers up to: []"
     ]
    }
   ],
   "source": [
    "from torchinfo import summary\n",
    "\n",
    "# Assuming CpGPredictor model is defined and loaded as model\n",
    "model = CpGPredictor(input_size=5, hidden_size=128, num_layers=1, output_size=1)\n",
    "\n",
    "# Print the model summary for an input size (e.g., a batch size of 32, sequence length 128)\n",
    "summary(model, input_size=(128,))  # (batch_size, sequence_length)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "super(type, obj): obj must be an instance or subtype of type",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[64], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mCpGPredictor1\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhidden_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mLSTM_HIDDEN\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_layers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mLSTM_LAYER\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m model\n",
      "Cell \u001b[1;32mIn[60], line 4\u001b[0m, in \u001b[0;36mCpGPredictor1.__init__\u001b[1;34m(self, input_size, hidden_size, num_layers, output_size)\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, input_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, hidden_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m128\u001b[39m, num_layers\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, output_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m----> 4\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mCpGPredictor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m()\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membedding \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mEmbedding(\u001b[38;5;241m5\u001b[39m, input_size)  \u001b[38;5;66;03m# Embedding layer for input sequence\u001b[39;00m\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlstm \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mLSTM(input_size, hidden_size, num_layers, batch_first\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[1;31mTypeError\u001b[0m: super(type, obj): obj must be an instance or subtype of type"
     ]
    }
   ],
   "source": [
    "model = CpGPredictor1(input_size=5, hidden_size=LSTM_HIDDEN, num_layers=LSTM_LAYER, output_size=1)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model has 201345 trainable parameters\n"
     ]
    }
   ],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "# Get the number of parameters\n",
    "num_params = count_parameters(model)\n",
    "print(f'The model has {num_params} trainable parameters')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "super(type, obj): obj must be an instance or subtype of type",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[65], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# init model / loss function / optimizer etc.\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mCpGPredictor1\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mLSTM_HIDDEN\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mLSTM_LAYER\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_size\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m loss_fn \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mMSELoss()\n\u001b[0;32m      5\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mAdam(model\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39mlearning_rate)\n",
      "Cell \u001b[1;32mIn[60], line 4\u001b[0m, in \u001b[0;36mCpGPredictor1.__init__\u001b[1;34m(self, input_size, hidden_size, num_layers, output_size)\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, input_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, hidden_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m128\u001b[39m, num_layers\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, output_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m----> 4\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mCpGPredictor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m()\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membedding \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mEmbedding(\u001b[38;5;241m5\u001b[39m, input_size)  \u001b[38;5;66;03m# Embedding layer for input sequence\u001b[39;00m\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlstm \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mLSTM(input_size, hidden_size, num_layers, batch_first\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[1;31mTypeError\u001b[0m: super(type, obj): obj must be an instance or subtype of type"
     ]
    }
   ],
   "source": [
    "# init model / loss function / optimizer etc.\n",
    "\n",
    "model = CpGPredictor1(input_size, LSTM_HIDDEN, LSTM_LAYER, output_size)\n",
    "loss_fn = torch.nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training (you can modify the code below)\n",
    "t_loss = .0\n",
    "model.train()\n",
    "model.zero_grad()\n",
    "for _ in range(epoch_num):\n",
    "    for batch in train_data_loader:\n",
    "        #TODO complete training loop\n",
    "        t_loss += loss.item()\n",
    "        loss.backward()\n",
    "\n",
    "    print(t_loss)\n",
    "    t_loss = .0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CpGPredictor(torch.nn.Module):\n",
    "    ''' Simple model that uses a LSTM to count the number of CpGs in a sequence '''\n",
    "    def __init__(self, input_size, hidden_size, num_layers, output_size):\n",
    "        super(CpGPredictor, self).__init__()\n",
    "        # We do need a lstm and a classifier layer here but you are free to implement them in your way\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.embedding = torch.nn.Embedding(5, input_size)\n",
    "        self.lstm = torch.nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.fc = torch.nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x)\n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
    "        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
    "        out, _ = self.lstm(x, (h0, c0))\n",
    "        out = self.fc(out[:, -1, :])\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CpGPredictor(input_size, LSTM_HIDDEN, LSTM_LAYER, output_size)\n",
    "loss_fn = torch.nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20, Loss: 9.990298725664616\n",
      "Epoch 2/20, Loss: 4.216798312962055\n",
      "Epoch 3/20, Loss: 4.192945018410683\n",
      "Epoch 4/20, Loss: 4.1402736976742744\n",
      "Epoch 5/20, Loss: 3.9744697585701942\n",
      "Epoch 6/20, Loss: 3.8071797639131546\n",
      "Epoch 7/20, Loss: 3.259594563394785\n",
      "Epoch 8/20, Loss: 2.1341355107724667\n",
      "Epoch 9/20, Loss: 1.0653156340122223\n",
      "Epoch 10/20, Loss: 0.7300802897661924\n",
      "Epoch 11/20, Loss: 0.5070901606231928\n",
      "Epoch 12/20, Loss: 0.36563044413924217\n",
      "Epoch 13/20, Loss: 0.2792621161788702\n",
      "Epoch 14/20, Loss: 0.20765071082860231\n",
      "Epoch 15/20, Loss: 0.20905277412384748\n",
      "Epoch 16/20, Loss: 0.14201264269649982\n",
      "Epoch 17/20, Loss: 0.10674727987498045\n",
      "Epoch 18/20, Loss: 0.08013340027537197\n",
      "Epoch 19/20, Loss: 0.06362906843423843\n",
      "Epoch 20/20, Loss: 0.05347717896802351\n"
     ]
    }
   ],
   "source": [
    "graph_losses = []\n",
    "for epoch in range(epoch_num):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for batch_x, batch_y in train_data_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(batch_x)\n",
    "        loss = loss_fn(outputs, batch_y.float().unsqueeze(1))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    epoch_loss = total_loss / len(train_data_loader)\n",
    "    graph_losses.append(epoch_loss)\n",
    "    print(f\"Epoch {epoch+1}/{epoch_num}, Loss: {epoch_loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'CpGPredictor' object has no attribute 'embedding'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[59], line 7\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch_x, batch_y \u001b[38;5;129;01min\u001b[39;00m train_data_loader:\n\u001b[0;32m      6\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m----> 7\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_x\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      8\u001b[0m     loss \u001b[38;5;241m=\u001b[39m loss_fn(outputs, batch_y\u001b[38;5;241m.\u001b[39mfloat()\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m1\u001b[39m))\n\u001b[0;32m      9\u001b[0m     loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[1;32me:\\python_project\\proj_env\\lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32me:\\python_project\\proj_env\\lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "Cell \u001b[1;32mIn[47], line 12\u001b[0m, in \u001b[0;36mCpGPredictor.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m---> 12\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membedding\u001b[49m(x)\n\u001b[0;32m     13\u001b[0m     h0 \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mzeros(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_layers, x\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhidden_size)\u001b[38;5;241m.\u001b[39mto(x\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m     14\u001b[0m     c0 \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mzeros(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_layers, x\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhidden_size)\u001b[38;5;241m.\u001b[39mto(x\u001b[38;5;241m.\u001b[39mdevice)\n",
      "File \u001b[1;32me:\\python_project\\proj_env\\lib\\site-packages\\torch\\nn\\modules\\module.py:1931\u001b[0m, in \u001b[0;36mModule.__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   1929\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m modules:\n\u001b[0;32m   1930\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m modules[name]\n\u001b[1;32m-> 1931\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\n\u001b[0;32m   1932\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m object has no attribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1933\u001b[0m )\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'CpGPredictor' object has no attribute 'embedding'"
     ]
    }
   ],
   "source": [
    "graph_losses = []\n",
    "for epoch in range(epoch_num):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for batch_x, batch_y in train_data_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(batch_x)\n",
    "        loss = loss_fn(outputs, batch_y.float().unsqueeze(1))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    epoch_loss = total_loss / len(train_data_loader)\n",
    "    graph_losses.append(epoch_loss)\n",
    "    print(f\"Epoch {epoch+1}/{epoch_num}, Loss: {epoch_loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# eval (you can modify the code below)\n",
    "model.eval()\n",
    "\n",
    "res_gs = []\n",
    "res_pred = []\n",
    "\n",
    "for batch in test_data_loader:\n",
    "    # TODO complete inference loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.4357474483549595\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "total_loss = 0\n",
    "with torch.no_grad():\n",
    "    for batch_x, batch_y in test_data_loader:\n",
    "        outputs = model(batch_x)\n",
    "        loss = loss_fn(outputs, batch_y.float().unsqueeze(1))\n",
    "        total_loss += loss.item()\n",
    "\n",
    "print(f\"Test Loss: {total_loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall Accuracy: 0.84\n"
     ]
    }
   ],
   "source": [
    "# Compute accuracy on new set of test samples by running predictions\n",
    "N = 100\n",
    "test_x, test_y = prepare_data(N)\n",
    "\n",
    "# Convert data to PyTorch tensors\n",
    "test_x = torch.tensor(test_x)\n",
    "test_y = torch.tensor(test_y)\n",
    "\n",
    "# Run predictions for each sequence and compute overall accuracy\n",
    "correct_predictions = 0\n",
    "for sequence, y in zip(test_x, test_y):\n",
    "    # Perform inference\n",
    "    with torch.no_grad():\n",
    "        output = model(sequence.unsqueeze(0))\n",
    "    # Convert output to CpG count\n",
    "    predicted_cpg_count = output.item()\n",
    "    # Check if prediction is within a tolerance of 0.5\n",
    "    if abs(predicted_cpg_count - (y.float().unsqueeze(0))) <= 0.3:\n",
    "        correct_predictions += 1\n",
    "\n",
    "# Compute overall accuracy\n",
    "accuracy = correct_predictions / N\n",
    "print(\"Overall Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"model.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TMrRf_aVDRJm"
   },
   "source": [
    "# Part 2: what if the DNA sequences are not the same length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hint we will need following imports\n",
    "from torch.nn.utils.rnn import pad_sequence, pack_padded_sequence, pad_packed_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AKvG-MNuXJr9"
   },
   "outputs": [],
   "source": [
    "# DO NOT CHANGE HERE\n",
    "random.seed(13)\n",
    "\n",
    "# Use this for getting x label\n",
    "def rand_sequence_var_len(n_seqs: int, lb: int=16, ub: int=128) -> Sequence[int]:\n",
    "    for i in range(n_seqs):\n",
    "        seq_len = random.randint(lb, ub)\n",
    "        yield [random.randint(1, 5) for _ in range(seq_len)]\n",
    "\n",
    "\n",
    "# Use this for getting y label\n",
    "def count_cpgs(seq: str) -> int:\n",
    "    cgs = 0\n",
    "    for i in range(0, len(seq) - 1):\n",
    "        dimer = seq[i:i+2]\n",
    "        # note that seq is a string, not a list\n",
    "        if dimer == \"CG\":\n",
    "            cgs += 1\n",
    "    return cgs\n",
    "\n",
    "\n",
    "# Alphabet helpers   \n",
    "alphabet = 'NACGT'\n",
    "dna2int = {a: i for a, i in zip(alphabet, range(1, 6))}\n",
    "int2dna = {i: a for a, i in zip(alphabet, range(1, 6))}\n",
    "dna2int.update({\"pad\": 0})\n",
    "int2dna.update({0: \"<pad>\"})\n",
    "\n",
    "intseq_to_dnaseq = partial(map, int2dna.get)\n",
    "dnaseq_to_intseq = partial(map, dna2int.get)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO complete the task based on the change\n",
    "def prepare_data(num_samples=100, min_len=16, max_len=128):\n",
    "    # TODO prepared the training and test data\n",
    "    # you need to call rand_sequence and count_cpgs here to create the dataset\n",
    "    #step 1\n",
    "    X_dna_seqs_train = list(rand_sequence_var_len(num_samples, min_len, max_len))\n",
    "    #step 2\n",
    "    temp = ???\n",
    "    #step3\n",
    "    y_dna_seqs = ???\n",
    "    \n",
    "    return X_dna_seqs_train, y_dna_seqs\n",
    "    \n",
    "    \n",
    "min_len, max_len = 64, 128\n",
    "train_x, train_y = prepare_data(2048, min_len, max_len)\n",
    "test_x, test_y = prepare_data(512, min_len, max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, lists, labels) -> None:\n",
    "        self.lists = lists\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return torch.LongTensor(self.lists[index]), self.labels[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.lists)\n",
    "\n",
    "    \n",
    "# this will be a collate_fn for dataloader to pad sequence  \n",
    "class PadSequence:\n",
    "    #TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO complete the rest"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Xi Yangs Copy of broken-nn-template.ipynb",
   "provenance": [
    {
     "file_id": "13GlbI_pdKNES8I718iwl1KNnMZ73iOOn",
     "timestamp": 1651680757732
    }
   ]
  },
  "kernelspec": {
   "display_name": "proj_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
